{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Homework 2: Nannon\n",
    "### By Ari Porad\n",
    "### For COSI 101A with Professor Jordan Pollack, April 12th 2021"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discussion\n",
    "\n",
    "For this assignment, I built an implementation of the game Nannon and several different algorithms that could play it. Some high-level discussion of my approach follows in this section, then I'll walk through my implementation in more detail.\n",
    "\n",
    "### Representation\n",
    "\n",
    "I'm a big believer that if you choose your data structures right, the rest of your program writes itself. (That's a rough quote from someone, but I can't figure out who.) To that end, I spent a substantial amount of time during this project iterating on my data structures. Originally, I stored the board as a list, where each item in the list represented a position on the board. Legal values were `0` (spot is empty), `1` (current player's checker), and `-1` (opponent's checker). Checkers in the home and goal zones were stored separately. That data structure was simple, which was nice. However, it was easy to get into an illegal state (wrong number of checkers), which I didn't like--a good data structure is one that can't represent an illegal state, after all. It was also hard to manipulate, with lots of loops looking for checkers. I ultimately decided to switch to a representation with an (unordered) list of `Checker`s, each of which has a `Player` (black or white) and a `Position`. Initially, I attempted to have each checker's position be relative _to that checker's home_, which meant that the representation was entirely perspective-independent. That ended up being too complicated to manage, so I settled on a perspective-dependent representation where all checker positions are measured relative to one player's (the perspective player's) home. I'm still not satisfied with this representation--it simultaneously feels a little too complicated, while also needing too much perspective swapping--but it's good enough.\n",
    "\n",
    "The list of checkers (which is always `2 * checkers_per_player` long) is encapsulated by a `Board`, which also tracks the perspective (if the perspective is Black, then lower indexes are closer to Black's home and vis versa) and `GameConfiguration` (the variant of Nannon, such as `{6,3,6}` or `{8,4,6}`). `Board` contains much of the game logic, including calculating open spots, legal `Move`s, and the winner. The `Move` class trackes a possible move, and is responsible for properly executing it and returning the resulting `Board`. Finally, a `Dicestream` class wraps various iterators that can provide a stream of dice rolls.\n",
    "\n",
    "### Knowledge-Based Player\n",
    "\n",
    "### Sticking Points\n",
    "\n",
    "As mentioned above, picking (and iterating on) a set of datastructures was a big sticking point for this assignment. Building a knowledge-based player was also more difficult than anticipated--the strategies that I intuitively expected to work well weren't actually that effective, whereas the very simple score-based player was actually quite good (as, somewhat surprisingly, the simple last-piece-first player). It's also quite possible that I'm just bad at Nannon--as any of my friends or family can attest, I'm not generally not one for playing games like these the old-fashion way. Additionally, I ran into some very very strange situations that I think are bugs in the Python interpreter, which are more thoroughly document in `cli.py`--but basically, `Player.BLACK.long_str` would sometimes return `'White'`, but only in the PyCharm debugger and inconsistently. That was a fun one.\n",
    "\n",
    "## Running the Code\n",
    "\n",
    "I hope I've provided enough information in this report that--as requested--you won't need to run the code. If you do, however, there are a couple of ways to do so.\n",
    "\n",
    "First, much of the code, especially the game foundation, is unit tested through Python's [doctest][]. Tests can be run from the command line:\n",
    "\n",
    "```bash\n",
    "# This prints nothing if the tests pass\n",
    "$ python3 -m doctest src/*.py\n",
    "```\n",
    "\n",
    "Additionally, I built a simple CLI for interacting with the game system:\n",
    "\n",
    "```bash\n",
    "$ python3 src/cli.py --help\n",
    "usage: cli.py [-h] [-n ROUNDS] [-b BOARD_SIZE] [-c CHECKERS] [-d DIE_SIZE] [-s SEED]\n",
    "              {g,game,t,tournament,r,roundrobin} {first,human,knowledge,last,random,score} [{first,human,knowledge,last,random,score} ...]\n",
    "\n",
    "positional arguments:\n",
    "  {g,game,t,tournament,r,roundrobin}\n",
    "                        game mode\n",
    "  {first,human,knowledge,last,random,score}\n",
    "                        player algorithms (2 for game our tournament, 2+ for round robin)\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -n ROUNDS, --rounds ROUNDS\n",
    "                        number of matches to run\n",
    "  -b BOARD_SIZE, --board-size BOARD_SIZE\n",
    "                        board size\n",
    "  -c CHECKERS, --checkers CHECKERS\n",
    "                        checkers per player\n",
    "  -d DIE_SIZE, --die-size DIE_SIZE\n",
    "                        die size\n",
    "  -s SEED, --seed SEED  the seed for the random roll generator\n",
    "\n",
    "$ python3 src/cli.py game random human  # play against a random player\n",
    "<Output not shown because it requires humna input>\n",
    "\n",
    "$ python3 src/cli.py tournament random first last score -n 3000  # run a tournament and show the aggregate results\n",
    "Playing a Nannon{6,3,6} bulk tournament of 3000 games each between random, first, last, score. seed = 1618284126\n",
    "Played 6 tournaments of 3000 games each. Took 3s.\n",
    "Loser → | first   | last    | random  | score\n",
    "-----------------------------------------------\n",
    "random  | 53.5%   | 45.8%   | -       | 46.8%\n",
    "first   | -       | 44.9%   | 46.5%   | 43.0%\n",
    "last    | 55.1%   | -       | 54.2%   | 50.2%\n",
    "score   | 57.0%   | 49.8%   | 53.2%   | -\n",
    "\n",
    "$ python3 src/cli.py tournament last score first --seed 12345  # set the seed to any integer for consistent dice (doesn't affect the random player's decisions). We'll use the same seed as above\n",
    "Playing a Nannon{6,3,6} bulk tournament of 100 games each between last, score, first. seed = 12345\n",
    "Played 3 tournaments of 100 games each. Took 0s.\n",
    "Loser → | first   | last    | score\n",
    "-------------------------------------\n",
    "last    | 55.0%   | -       | 48.0%\n",
    "score   | 52.0%   | 52.0%   | -\n",
    "first   | -       | 45.0%   | 48.0%\n",
    "```\n",
    "\n",
    "[doctest]: https://docs.python.org/3/library/doctest.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "\n",
    "First off, let's run a round-robin tournament and look at the results. We'll run a lot of matches to get more consistent results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing a Nannon{6,3,6} bulk tournament of 10000 games each between last, first, score, random, knowledge. seed = 1618284674\n",
      "Played 10 tournaments of 10000 games each. Took 12s.                                                                              \n",
      "Loser →   | first     | knowledge | last      | random    | score    \n",
      "---------------------------------------------------------------------\n",
      "last      | 58.0%     | 52.4%     | -         | 52.7%     | 50.9%    \n",
      "first     | -         | 44.3%     | 42.0%     | 47.2%     | 43.5%    \n",
      "score     | 56.5%     | 51.9%     | 49.1%     | 53.6%     | -        \n",
      "random    | 52.8%     | 47.4%     | 47.3%     | -         | 46.4%    \n",
      "knowledge | 55.7%     | -         | 47.6%     | 52.6%     | 48.1%    \n"
     ]
    }
   ],
   "source": [
    "from bulk_tournament import bulk_tournament\n",
    "from structs import *\n",
    "from players import *\n",
    "\n",
    "results = bulk_tournament([LastPlayerAlgorithm(), FirstPlayerAlgorithm(), ScorePlayerAlgorithm(), RandomPlayerAlgorithm(), KnowledgePlayerAlgorithm()], rounds=10000, config=GameConfiguration(6, 3, 6))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That ran each a 10,000 game match between each of 5 players (for total of 100,000 matches), showing that (for example), the `knowledge` algorithm triumphs over the `andom`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}